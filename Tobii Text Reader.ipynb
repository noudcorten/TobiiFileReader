{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "import pickle\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'test11.txt'\n",
    "n_participants = 12\n",
    "f = open(file, 'r')\n",
    "all_values = []\n",
    "for i, line in enumerate(f): \n",
    "    if i == 0:\n",
    "        names = line.split('\\t')\n",
    "    elif i < n_participants+1:\n",
    "        values = line.split('\\t')\n",
    "        all_values.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class object():\n",
    "    def __init__(self, Name):\n",
    "        self.Name = Name\n",
    "        self.N = 0\n",
    "        self.Mean = 0\n",
    "        self.Sum = 0\n",
    "        self.times_visited = 0\n",
    "        \n",
    "    def set_N(self, N):\n",
    "        self.N += float(N)\n",
    "        self.times_visited += 1\n",
    "    \n",
    "    def set_Mean(self, Mean):\n",
    "        self.Mean += float(Mean)\n",
    "        self.times_visited += 1\n",
    "        \n",
    "    def set_Sum(self, Sum):\n",
    "        self.Sum += float(Sum)\n",
    "        self.times_visited += 1\n",
    "        \n",
    "    def get_Name(self):\n",
    "        return self.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_object(values, i, obj, object_info):\n",
    "    if object_info == 'N':\n",
    "        obj.set_N(values[i])\n",
    "    elif object_info == 'Mean':\n",
    "        obj.set_Mean(values[i])\n",
    "    elif object_info == 'Sum':\n",
    "        obj.set_Sum(values[i])\n",
    "    return obj\n",
    "\n",
    "def object_in_list(obj_list, object_name):\n",
    "    for obj in obj_list:\n",
    "        if obj.get_Name() == object_name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "all_info = []\n",
    "for values in all_values:\n",
    "    info_dict = {}\n",
    "    for i, name in enumerate(names):\n",
    "        name_list = name.split('_')\n",
    "        if i > 0:\n",
    "            page_list = name_list[1].split('/')\n",
    "\n",
    "            # N/google/search/youtube/baldibale\n",
    "            page_name = page_list[-1]\n",
    "            # Rectangle 11\n",
    "            object_name = name_list[-2]\n",
    "            # N, Mean, Sum\n",
    "            object_info = name_list[-1]\n",
    "            # Time to first fixation\n",
    "            info_type = name_list[0]\n",
    "\n",
    "            # if page in dict\n",
    "            if page_name in info_dict:\n",
    "                # if type in dict[page]\n",
    "                if info_type in info_dict[page_name]:\n",
    "                    obj_list = info_dict[page_name][info_type]\n",
    "                    # if there is a object with the same name\n",
    "                    if object_in_list(obj_list, object_name):\n",
    "                        for obj in obj_list:\n",
    "                            if obj.get_Name() == object_name:\n",
    "                                obj = set_object(values, i, obj, object_info)\n",
    "                                break\n",
    "                    # if there is no object with the same name\n",
    "                    else:\n",
    "                        obj = object(object_name)\n",
    "                        obj = set_object(values, i, obj, object_info)\n",
    "                        info_dict[page_name][info_type].append(obj)\n",
    "                # if type not in dict[page]\n",
    "                else:\n",
    "                    obj = object(object_name)\n",
    "                    obj = set_object(values, i, obj, object_info)\n",
    "                    info_dict[page_name][info_type] = [obj]\n",
    "            # if page not in dict\n",
    "            else:\n",
    "                obj = object(object_name)\n",
    "                obj = set_object(values, i, obj, object_info)\n",
    "                info_dict[page_name] = {info_type: [obj]}\n",
    "    \n",
    "    all_info.append(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING PREVIOUS ANSWERS \n",
      "\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "rect_info = {}\n",
    "if path.exists('obj/' + \"rectangle_info\" + '.pkl'):\n",
    "    print(\"LOADING PREVIOUS ANSWERS \\n\")\n",
    "    with open('obj/' + \"rectangle_info\" + '.pkl', 'rb') as f:\n",
    "        rect_info = pickle.load(f)\n",
    "else:\n",
    "    os.mkdir('obj/')\n",
    "\n",
    "all_grouped_info = []\n",
    "for info_dict in all_info:\n",
    "    grouped_dict = {}\n",
    "    for page in info_dict.keys():\n",
    "        grouped_dict[page] = {}\n",
    "        if page == 'B%20-%20patron%20saint%20of%20mental%20illness%20-%20Google%20Search.html?q=patron+saint+of+mental+illness&btnK=Google+Search (CRC)':\n",
    "            titles, descriptions, verticals = 10, 20, 24\n",
    "        elif page in rect_info:\n",
    "            titles, descriptions, verticals = rect_info[page]\n",
    "        else:\n",
    "            titles = int(input(\"titles: \"))\n",
    "            descriptions = int(input(\"descriptions: \"))\n",
    "            verticals = int(input(\"verticals: \"))\n",
    "            rect_info[page] = [titles, descriptions, verticals]\n",
    "\n",
    "        for info_type in info_dict[page].keys():\n",
    "            grouped_dict[page][info_type] = {} \n",
    "            obj_list = info_dict[page][info_type] # list with objects\n",
    "            title_list, descr_list, vert_list = [], [], []\n",
    "\n",
    "            for obj in obj_list:\n",
    "                name = obj.get_Name()\n",
    "                num = int(name.split(' ')[1])\n",
    "#                 if page == 'B%20-%20patron%20saint%20of%20mental%20illness%20-%20Google%20Search.html?q=patron+saint+of+mental+illness&btnK=Google+Search (CRC)':\n",
    "#                     print(num)\n",
    "                \n",
    "                if titles >= num > 0:\n",
    "                    title_list.append(obj)\n",
    "                elif descriptions >= num > titles:\n",
    "                    descr_list.append(obj)\n",
    "                elif verticals >= num > descriptions:\n",
    "#                     if page == 'B%20-%20patron%20saint%20of%20mental%20illness%20-%20Google%20Search.html?q=patron+saint+of+mental+illness&btnK=Google+Search (CRC)':\n",
    "#                         print('dit is een vertical')\n",
    "                    vert_list.append(obj)\n",
    "                elif num > verticals:\n",
    "#                     if page == 'B%20-%20patron%20saint%20of%20mental%20illness%20-%20Google%20Search.html?q=patron+saint+of+mental+illness&btnK=Google+Search (CRC)':\n",
    "#                         print(page)\n",
    "#                         print(total_time)\n",
    "                    total_time = obj.Sum\n",
    "                    \n",
    "#             print('\\n')\n",
    "            grouped_dict[page][info_type]['titles'] = title_list  \n",
    "            grouped_dict[page][info_type]['description'] = descr_list\n",
    "            grouped_dict[page][info_type]['verticals'] = vert_list\n",
    "            grouped_dict[page][info_type]['total_time'] = total_time\n",
    "    all_grouped_info.append(grouped_dict)\n",
    "    print('Done')\n",
    "with open('obj/'+ \"rectangle_info\" + '.pkl', 'wb+') as f:\n",
    "    pickle.dump(rect_info, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N = amount of participants that saw the rectangle\n",
    "# Sum = total time spent on rectangle\n",
    "# Mean = Sum / N\n",
    "\n",
    "all_blended, all_non_blended = [], [] # participant -> page -> tf, ff -> category -> [obj]\n",
    "for grouped_dict in all_grouped_info:\n",
    "    blended, non_blended = {}, {}\n",
    "    for page in grouped_dict.keys():\n",
    "        page_name = page.split(' ')[0]\n",
    "        if page_name == 'benefits':\n",
    "            page_type = 'NB'\n",
    "        elif page_name == 'black':\n",
    "            page_type = 'B'\n",
    "        elif page_name == 'facebook':\n",
    "            page_type = 'B'\n",
    "        elif page_name == 'feet':\n",
    "            page_type = 'B'\n",
    "        elif page_name == 'unicef':\n",
    "            page_type = 'NB'\n",
    "        elif page_name == 'why':\n",
    "            page_type = 'NB'\n",
    "        else:\n",
    "            page_type = page.split('%')[0]\n",
    "\n",
    "        if page_type == 'B':\n",
    "            blended[page] = grouped_dict[page]\n",
    "        if page_type == 'NB':\n",
    "            non_blended[page] = grouped_dict[page]\n",
    "    all_blended.append(blended)\n",
    "    all_non_blended.append(non_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_fix_per_category(list):\n",
    "    ff_per_category = []\n",
    "    for dict in list:\n",
    "        info = {}\n",
    "        for page in dict:\n",
    "            for info_type in dict[page]:\n",
    "                if info_type == 'Time to First Fixation':\n",
    "                    for rectangle_type in dict[page][info_type]:\n",
    "                        if rectangle_type != 'total_time':\n",
    "                            if rectangle_type not in info:\n",
    "                                info[rectangle_type] = []\n",
    "                            lowest_mean = math.inf\n",
    "                            for rectangle in dict[page][info_type][rectangle_type]:\n",
    "                                if rectangle.Mean < lowest_mean and rectangle.Mean != 0:\n",
    "                                    lowest_mean = rectangle.Mean\n",
    "                            info[rectangle_type].append(lowest_mean)\n",
    "                else:\n",
    "                    continue\n",
    "        ff_per_category.append(info)\n",
    "    return ff_per_category\n",
    "\n",
    "# participant -> lowest first fix per category per page\n",
    "ff_blended = first_fix_per_category(all_blended)\n",
    "ff_non_blended = first_fix_per_category(all_non_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ff_means(list):\n",
    "    info = {}\n",
    "    for dict in list:\n",
    "        for category in dict:\n",
    "            ff_list = dict[category]\n",
    "            if category not in info:\n",
    "                info[category] = []\n",
    "            clean_ff_list = [x for x in ff_list if x!=math.inf]\n",
    "            if clean_ff_list:\n",
    "                mean = np.mean(np.array(clean_ff_list))\n",
    "            else:\n",
    "                mean = 0\n",
    "            info[category].append(mean)\n",
    "    return info\n",
    "\n",
    "ff_blended_means = get_ff_means(ff_blended)\n",
    "ff_non_blended_means = get_ff_means(ff_non_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_fix_category_amount(list):\n",
    "    count = [0, 0, 0]\n",
    "    for dict in list:\n",
    "        for i, key in enumerate(dict):\n",
    "            if i == 0:\n",
    "                arr = np.array(dict[key])\n",
    "            else:\n",
    "                cat = np.array(dict[key])\n",
    "                arr = np.vstack((arr, cat))\n",
    "        for i in range(len(arr[0,:])):\n",
    "            if np.all(arr[:,i] == [math.inf, math.inf, math.inf]):\n",
    "                continue\n",
    "            result = np.where(arr[:, i] == np.amin(arr[:, i]))\n",
    "            index = int(result[0][0])\n",
    "            count[index] += 1\n",
    "    return count\n",
    "\n",
    "# titles, descriptions, verticals\n",
    "ff_blended_amount = first_fix_category_amount(ff_blended)\n",
    "ff_non_blended_amount = first_fix_category_amount(ff_non_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_fix_per_link(list):\n",
    "    info = {}\n",
    "    for dict in list:\n",
    "        for page in dict:\n",
    "            for info_type in dict[page]:\n",
    "                if info_type == 'Total Fixation Duration':\n",
    "                    for category in dict[page][info_type]:\n",
    "                        if category != 'total_time' and category != 'verticals':\n",
    "                            if category not in info:\n",
    "                                info[category] = {}\n",
    "                            value_list = []\n",
    "                            obj_list = []\n",
    "                            for obj in dict[page][info_type][category]:\n",
    "                                num = int(obj.get_Name().split(' ')[1])\n",
    "                                value_list.append(num)\n",
    "                                obj_list.append(obj)\n",
    "                            \n",
    "                            sorted_list = value_list.copy()\n",
    "                            sorted_list.sort()\n",
    "                            \n",
    "                            for i, value in enumerate(sorted_list):\n",
    "                                index = value_list.index(value)\n",
    "                                obj = obj_list[index]\n",
    "                                if i not in info[category]:\n",
    "                                    info[category][i] = 0\n",
    "                                info[category][i] += obj.Sum\n",
    "                        else:\n",
    "                            continue\n",
    "                else:\n",
    "                    continue\n",
    "    return info\n",
    "\n",
    "# participant -> total fixation time per category per index\n",
    "tf_per_link_blended = total_fix_per_link(all_blended)\n",
    "tf_per_link_non_blended = total_fix_per_link(all_non_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_fix_per_category(list):\n",
    "    tf_per_category = []\n",
    "    for i, dict in enumerate(list):\n",
    "        info = {}\n",
    "        for page in dict:\n",
    "            for info_type in dict[page]:\n",
    "                if info_type == 'Total Fixation Duration':\n",
    "                    for rectangle_type in dict[page][info_type]:\n",
    "                        if rectangle_type not in info:\n",
    "                            info[rectangle_type] = []\n",
    "                        if rectangle_type != 'total_time':\n",
    "                            total_sum = 0   \n",
    "                            for rectangle in dict[page][info_type][rectangle_type]:\n",
    "                                total_sum += rectangle.Sum\n",
    "                            info[rectangle_type].append(total_sum)\n",
    "                        else:\n",
    "                            info[rectangle_type].append(dict[page][info_type][rectangle_type])\n",
    "                else:\n",
    "                    continue\n",
    "        tf_per_category.append(info)\n",
    "    return tf_per_category\n",
    "\n",
    "# participant -> total fix per category per page\n",
    "tf_blended = total_fix_per_category(all_blended)\n",
    "tf_non_blended = total_fix_per_category(all_non_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_means(list):\n",
    "    info = {}\n",
    "    for dict in list:\n",
    "        for category in dict:\n",
    "            tf_list = dict[category]\n",
    "            if category not in info:\n",
    "                info[category] = []\n",
    "            info[category].append(np.sum(tf_list)/6)\n",
    "    return info\n",
    "\n",
    "# mean per category per participant\n",
    "tf_blended_means = get_tf_means(tf_blended)\n",
    "tf_non_blended_means = get_tf_means(tf_non_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles\n",
      "0.21622653758759622\n",
      "0.24217090385801407\n",
      "0.09028347298983776\n",
      "0.2051256506687255\n",
      "0.13432360953687686\n",
      "0.10261088899025947\n",
      "0.23643434221632703\n",
      "0.10361345640666696\n",
      "0.12029206715894558\n",
      "0.14713168418444986\n",
      "0.19903882499055026\n",
      "0.022687122268712227\n",
      "\n",
      "\n",
      "description\n",
      "0.053980256248687256\n",
      "0.08531487699581991\n",
      "0.15660545551791763\n",
      "0.15758013499041118\n",
      "0.19837340173795465\n",
      "0.1831915635817211\n",
      "0.22576269142650432\n",
      "0.1916969246248742\n",
      "0.26694443298543785\n",
      "0.035017871677814345\n",
      "0.2641251327465486\n",
      "0.10878661087866108\n",
      "\n",
      "\n",
      "verticals\n",
      "0.4631761852933876\n",
      "0.3871719317480984\n",
      "0.5817079693349972\n",
      "0.37682747627705404\n",
      "0.41716876454095325\n",
      "0.6115061582633429\n",
      "0.2845321355359942\n",
      "0.5435495865960891\n",
      "0.33088568953426006\n",
      "0.6587040379375023\n",
      "0.3109599150422089\n",
      "0.7814659848132651\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_tf_percentage(list):\n",
    "    info = {}\n",
    "    for i, dict in enumerate(list):\n",
    "        for category in dict:\n",
    "            if category != 'total_time':\n",
    "                tf_list = dict[category]\n",
    "                if category not in info:\n",
    "                    info[category] = []            \n",
    "                cat_time = np.sum(tf_list)\n",
    "                total_time = np.sum(dict['total_time'])\n",
    "                percentage = cat_time/total_time\n",
    "                info[category].append(percentage)\n",
    "            else:\n",
    "                continue\n",
    "    return info\n",
    "\n",
    "tf_blended_percentage = get_tf_percentage(tf_blended)\n",
    "tf_non_blended_percentage = get_tf_percentage(tf_non_blended)\n",
    "# tf_blended_percentage\n",
    "\n",
    "for key in tf_blended_percentage:\n",
    "    print(key)\n",
    "    for item in tf_blended_percentage[key]:\n",
    "        print(item)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
